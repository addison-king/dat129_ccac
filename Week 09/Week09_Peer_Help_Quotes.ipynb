{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('J.K. Rowling', 8), ('Albert Einstein', 7), ('Marilyn Monroe', 6), ('Dr. Seuss', 6), ('Mark Twain', 6), ('C.S. Lewis', 5), ('Jane Austen', 4), ('Bob Marley', 3), ('Ralph Waldo Emerson', 2), ('Mother Teresa', 2), ('George R.R. Martin', 2), ('Ernest Hemingway', 2), ('Charles Bukowski', 2), ('Suzanne Collins', 2), ('Douglas Adams', 1), ('Elie Wiesel', 1), ('Friedrich Nietzsche', 1), ('Allen Saunders', 1), ('Pablo Neruda', 1), ('Garrison Keillor', 1), ('Jim Henson', 1), ('Charles M. Schulz', 1), ('William Nicholson', 1), ('Jorge Luis Borges', 1), ('George Eliot', 1), ('Martin Luther King Jr.', 1), ('James Baldwin', 1), ('Eleanor Roosevelt', 1), ('Haruki Murakami', 1), ('Alexandre Dumas fils', 1), ('Stephenie Meyer', 1), ('Helen Keller', 1), ('George Bernard Shaw', 1), ('J.R.R. Tolkien', 1), ('Alfred Tennyson', 1), ('Terry Pratchett', 1), ('J.D. Salinger', 1), ('George Carlin', 1), ('John Lennon', 1), ('W.C. Fields', 1), ('Ayn Rand', 1), ('Jimi Hendrix', 1), ('J.M. Barrie', 1), ('E.E. Cummings', 1), ('Khaled Hosseini', 1), ('Harper Lee', 1), (\"Madeleine L'Engle\", 1)]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Brandyn Gilbert\n",
    "    Wed Mar 25 19:23:07 2020\n",
    "    Python 2 - DAT-129 - Spring 2020\n",
    "    Lecture Notes\n",
    "\"\"\"\n",
    "#PLAN\n",
    "\n",
    "import urllib\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def getSearchURL(page):\n",
    "    url = 'http://quotes.toscrape.com/page/%d/' %(page)\n",
    "    return url\n",
    "\n",
    "def getPageText(url):\n",
    "    req = urllib.request.Request(url)\n",
    "    with urllib.request.urlopen(req) as response:\n",
    "        return response.read()\n",
    "\n",
    "def main():\n",
    "    author_dict = {}\n",
    "    page = 1\n",
    "    while page < 6:\n",
    "        \n",
    "        #print('\\nPage: ', page)\n",
    "        page += 1\n",
    "        url = getSearchURL(page)\n",
    "        pageText = getPageText(url)\n",
    "\n",
    "        soup = BeautifulSoup(pageText, 'html.parser')\n",
    "        quotes = soup.find_all('div', 'quote')\n",
    "        for quo in quotes:\n",
    "            author = quo.find('small', 'author').text\n",
    "            if author not in author_dict:\n",
    "                author_dict[author] = 1\n",
    "            else:\n",
    "                author_dict[author] += 1\n",
    "            # print(author)\n",
    "        \n",
    "       \n",
    "    winner = (sorted(author_dict.items(), key = lambda x: int(x[1]), reverse  = True))\n",
    "    print(winner)\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
